{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ6HT69itq5U",
        "outputId": "dc068be1-3296-4329-ce62-8506bf69ea49"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2oUzxHg2lto"
      },
      "source": [
        "# 1. Set up\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TH8rnJqvUfk"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.52.4\n",
        "!pip install -q bitsandbytes==0.46.0\n",
        "!pip install -q accelerate==1.7.0\n",
        "!pip install -q langchain==0.3.25\n",
        "!pip install -q langchainhub==0.1.21\n",
        "!pip install -q langchain-chroma==0.2.4\n",
        "!pip install -q langchain_experimental==0.3.4\n",
        "!pip install -q langchain-community==0.3.24\n",
        "!pip install -q langchain_huggingface==0.2.0\n",
        "!pip install -q python-dotenv==1.1.0\n",
        "!pip install -q pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_Hnisfzvfjy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain import hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpa9SA3M0wYm",
        "outputId": "f0e149ce-a178-4d32-81e8-739ad8b7d7c2"
      },
      "outputs": [],
      "source": [
        "!gdown 1lWuq0COKnU9mCfMvTEq54DBLgAh3yYDx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1KzMsS92ke6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXllLSBH2qI1"
      },
      "source": [
        "# 2.Load file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyeXHLY6v7Gf"
      },
      "outputs": [],
      "source": [
        "Loader = PyPDFLoader\n",
        "file_path = \"/content/YOLOv10_Tutorials.pdf\"\n",
        "loader = Loader(file_path)\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZwsI3or2tqE"
      },
      "source": [
        "# 3. Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIh-2oPx3X-P"
      },
      "source": [
        "**Chọn model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgaPIeaFwwdS"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"bkai-foundation-models/vietnamese-bi-encoder\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3FV-3NhxNez",
        "outputId": "74b1909f-9383-4ddd-9f3f-966c60a6d3a2"
      },
      "outputs": [],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLFmSBV-3NIW"
      },
      "source": [
        "**Phương pháp phân đoạn tài liệu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2KLwk2_xSD5"
      },
      "outputs": [],
      "source": [
        "#Phan doan tai lieu\n",
        "\n",
        "semantic_splitter = SemanticChunker(\n",
        "    embeddings = embeddings, #embeddings model\n",
        "    breakpoint_threshold_type = \"percentile\",\n",
        "    breakpoint_threshold_amount = 95, #5% nho nhat => tách (ngưỡng lấy theo phân vị của phân phối)\n",
        "    min_chunk_size = 500, #mỗi một đoạn có ít nhất 500 kí tự\n",
        "    add_start_index = True, #khi mà tiến hành phân đoạn, đánh tham số thứ tự các đoạn bị phân ra\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFltXHk44Agl"
      },
      "source": [
        "**Chạy phân đoạn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5JsRdOdyZyJ"
      },
      "outputs": [],
      "source": [
        "docs = semantic_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YooQOByayq6b",
        "outputId": "013fe3c2-6db7-4eba-8d77-50331c945c2a"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0L02m_hyvIt",
        "outputId": "fd1f174e-ebd7-4204-9909-789f2e470e8d"
      },
      "outputs": [],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIy8C-mc4Mxn"
      },
      "source": [
        "**Lưu các đoạn thành vector trong cơ sở dữ liệu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIm_ALXIywD1",
        "outputId": "86dec181-1100-49a2-8b4f-2d5b7ea60476"
      },
      "outputs": [],
      "source": [
        "vector_db = Chroma.from_documents(\n",
        "    documents = docs,\n",
        "    embedding = embeddings, #chuyển docs -> vector / lưu trữ vector\n",
        ")#định nghĩa vector data base\n",
        "\n",
        "retriever = vector_db.as_retriever() # khởi tạo vector retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBizCNI5AaA"
      },
      "source": [
        "# 4. Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqC8mxl9zQ7K",
        "outputId": "a62ca9a3-0df5-434f-e5fe-ba03a9c74d0a"
      },
      "outputs": [],
      "source": [
        "query = \"YOLOv10 dùng để làm gì\"\n",
        "result = retriever.invoke(query) #invoke chuyển câu query thành vector, xong truy vấn\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCKasOnYzrYi",
        "outputId": "551ace39-0942-47e0-f831-6350892155d9"
      },
      "outputs": [],
      "source": [
        "print(len(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK3rZVpBzyZs",
        "outputId": "3c2355e3-7069-451a-c913-a5d101e3831b"
      },
      "outputs": [],
      "source": [
        "print(result[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY7J_VNa2Wun"
      },
      "source": [
        "# 5. LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "74d64024f3134bff9de5a74b016c465e",
            "721f0de8be334f9eba92d53b42641efb",
            "d73b132ad9c7406ea0937ed0ee44040b",
            "de817b71954442dbbc24da36871123ef",
            "f088a9462bee45ebafe97cb9e3f38cf7",
            "e6b21177907b42df88196db158796998",
            "67f5058891e7445aae685fd890858f02",
            "83b20f9c7ed345eead1612addf4fff58",
            "68e737338124406886eadc213e795e6c",
            "8d22f24bdeb24fb4b49e14ac53262c0c",
            "2a23b9dc7d4b4efd87308988543d3548"
          ]
        },
        "id": "uWOd8WXwz3vr",
        "outputId": "5f609cfe-8d8d-4333-f375-aa32e1fc9134"
      },
      "outputs": [],
      "source": [
        "nf4_config = BitsAndBytesConfig(\n",
        "    ### Your Code Here\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "    bnb_4bit_compute_dtype = torch.bfloat16, #quantization\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config = nf4_config,\n",
        "    device_map = \"auto\",\n",
        "    low_cpu_mem_usage = True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) #bộ tách từ\n",
        "\n",
        "model_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,# phản hồi tối đa sinh ra 512 token\n",
        "    pad_token_id=tokenizer.eos_token_id, # keyworkd đánh dấu kết thúc sinh\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline=model_pipeline,\n",
        ")\n",
        "#text đầu vào => tokenizer => model => generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4cxc0K-C7vc"
      },
      "source": [
        "# 6. Prompting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oYgjFm74Q_Y",
        "outputId": "7443a722-caad-4f8e-957e-0ef6e7f2c7e0"
      },
      "outputs": [],
      "source": [
        "#from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "# input variables = [context, question]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0SJ-KZ-DaZG"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2dHHTdN4mVi"
      },
      "outputs": [],
      "source": [
        "rag_chain = (\n",
        "    {\"content\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "#chain: retriever(content) -> format_docs(question) => RunnablePassthrough:\n",
        "#pass vào content question để tìm các đoạn phù hợp\n",
        "#Đẩy vào prompt -> chạy qua LLM ->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xoe-6EnE5qHB",
        "outputId": "63a7c2b0-1fec-45ef-b6eb-e188e1415fc6"
      },
      "outputs": [],
      "source": [
        "user_question = \"YOLOv10 là gì?\"\n",
        "output = rag_chain.invoke(user_question)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y-P1rtmFVSL"
      },
      "source": [
        "# 7.Streamlit Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-Iy8W7mFM54",
        "outputId": "cb855127-b2f7-4b37-8be0-661a1904b5f3"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit==1.46.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ch8jWkuFbiX",
        "outputId": "310c382f-e122-4e42-92fe-14ead73ff2f3"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "import torch\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import time\n",
        "\n",
        "if 'models_loaded' not in st.session_state:\n",
        "    st.session_state.models_loaded = None\n",
        "if 'rag_chain' not in st.session_state:\n",
        "    st.session_state.rag_chain = None\n",
        "if 'models_loaded' not in st.session_state:\n",
        "    st.session_state.models_loaded = False\n",
        "if 'embeddings' not in st.session_state:\n",
        "    st.session_state.embeddings = None\n",
        "if 'llm' not in st.session_state:\n",
        "    st.session_state.llm = None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_embeddings():\n",
        "    return HuggingFaceEmbeddings(model_name=\"bkai-foundation-models/vietnamese-bi-encoder\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_llm():\n",
        "    MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    model_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    return HuggingFacePipeline(pipeline=model_pipeline)\n",
        "\n",
        "def process_pdf(uploaded_file):\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
        "        tmp_file.write(uploaded_file.getvalue())\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    loader = PyPDFLoader(tmp_file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    semantic_splitter = SemanticChunker(\n",
        "        embeddings=st.session_state.embeddings,\n",
        "        buffer_size=1,\n",
        "        breakpoint_threshold_type=\"percentile\",\n",
        "        breakpoint_threshold_amount=95,\n",
        "        min_chunk_size=500,\n",
        "        add_start_index=True\n",
        "    )\n",
        "\n",
        "    docs = semantic_splitter.split_documents(documents)\n",
        "    vector_db = Chroma.from_documents(documents=docs, embedding=st.session_state.embeddings)\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | st.session_state.llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    os.unlink(tmp_file_path)\n",
        "    return rag_chain, len(docs)\n",
        "\n",
        "\n",
        "def add_message(role, content):\n",
        "    \"\"\"Thêm tin nhắn vào lịch sử chat\"\"\"\n",
        "    st.session_state.chat_history.append({\n",
        "        \"role\": role,\n",
        "        \"content\": content,\n",
        "        \"timestamp\": time.time()\n",
        "    })\n",
        "\n",
        "def clear_chat():\n",
        "    \"\"\"Xóa lịch sử chat\"\"\"\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "def display_chat():\n",
        "    \"\"\"Hiển thị lịch sử chat\"\"\"\n",
        "    if st.session_state.chat_history:\n",
        "        for message in st.session_state.chat_history:\n",
        "            if message[\"role\"] == \"user\":\n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(message[\"content\"])\n",
        "            else:\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    st.write(message[\"content\"])\n",
        "    else:\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.write(\"Xin chào! Tôi là AI assistant. Hãy upload file PDF và bắt đầu đặt câu hỏi về nội dung tài liệu nhé! 😊\")\n",
        "\n",
        "# UI\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"PDF RAG Chatbot\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "    st.title(\"PDF RAG Assistant\")\n",
        "    st.logo(\"./logo.png\", size=\"large\")\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.title(\"⚙️ Cài đặt\")\n",
        "\n",
        "        # Load models\n",
        "        if not st.session_state.models_loaded:\n",
        "            st.warning(\"⏳ Đang tải models...\")\n",
        "            with st.spinner(\"Đang tải AI models...\"):\n",
        "                st.session_state.embeddings = load_embeddings()\n",
        "                st.session_state.llm = load_llm()\n",
        "                st.session_state.models_loaded = True\n",
        "            st.success(\"✅ Models đã sẵn sàng!\")\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.success(\"✅ Models đã sẵn sàng!\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Upload PDF\n",
        "        st.subheader(\"📄 Upload tài liệu\")\n",
        "        uploaded_file = st.file_uploader(\"Chọn file PDF\", type=\"pdf\")\n",
        "\n",
        "        if uploaded_file:\n",
        "            if st.button(\"🔄 Xử lý PDF\", use_container_width=True):\n",
        "                with st.spinner(\"Đang xử lý PDF...\"):\n",
        "                    st.session_state.rag_chain, num_chunks = process_pdf(uploaded_file)\n",
        "                    st.session_state.pdf_processed = True\n",
        "                    st.session_state.pdf_name = uploaded_file.name\n",
        "                    # Reset chat history khi upload PDF mới\n",
        "                    clear_chat()\n",
        "                    add_message(\"assistant\", f\"✅ Đã xử lý thành công file **{uploaded_file.name}**!\\n\\n📊 Tài liệu được chia thành {num_chunks} phần. Bạn có thể bắt đầu đặt câu hỏi về nội dung tài liệu.\")\n",
        "                st.rerun()\n",
        "\n",
        "        # PDF status\n",
        "        if st.session_state.pdf_processed:\n",
        "            st.success(f\"📄 Đã tải: {st.session_state.pdf_name}\")\n",
        "        else:\n",
        "            st.info(\"📄 Chưa có tài liệu\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Chat controls\n",
        "        st.subheader(\"💬 Điều khiển Chat\")\n",
        "        if st.button(\"🗑️ Xóa lịch sử chat\", use_container_width=True):\n",
        "            clear_chat()\n",
        "            st.rerun()\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Instructions\n",
        "        st.subheader(\"📋 Hướng dẫn\")\n",
        "        st.markdown(\"\"\"\n",
        "        **Cách sử dụng:**\n",
        "        1. **Upload PDF** - Chọn file và nhấn \"Xử lý PDF\"\n",
        "        2. **Đặt câu hỏi** - Nhập câu hỏi trong ô chat\n",
        "        3. **Nhận trả lời** - AI sẽ trả lời dựa trên nội dung PDF\n",
        "        \"\"\")\n",
        "\n",
        "    # Main content\n",
        "    st.markdown(\"*Trò chuyện với Chatbot để trao đổi về nội dung tài liệu PDF của bạn*\")\n",
        "\n",
        "    # Chat container\n",
        "    chat_container = st.container()\n",
        "\n",
        "    with chat_container:\n",
        "        # Display chat history\n",
        "        display_chat()\n",
        "\n",
        "    # Chat input\n",
        "    if st.session_state.models_loaded:\n",
        "        if st.session_state.pdf_processed:\n",
        "            # User input\n",
        "            user_input = st.chat_input(\"Nhập câu hỏi của bạn...\")\n",
        "\n",
        "            if user_input:\n",
        "                # Add user message\n",
        "                add_message(\"user\", user_input)\n",
        "\n",
        "                # Display user message immediately\n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(user_input)\n",
        "\n",
        "                # Generate response\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    with st.spinner(\"Đang suy nghĩ...\"):\n",
        "                        try:\n",
        "                            output = st.session_state.rag_chain.invoke(user_input)\n",
        "                            # Clean up the response\n",
        "                            if 'Answer:' in output:\n",
        "                                answer = output.split('Answer:')[1].strip()\n",
        "                            else:\n",
        "                                answer = output.strip()\n",
        "\n",
        "                            # Display response\n",
        "                            st.write(answer)\n",
        "\n",
        "                            # Add assistant message to history\n",
        "                            add_message(\"assistant\", answer)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            error_msg = f\"Xin lỗi, đã có lỗi xảy ra: {str(e)}\"\n",
        "                            st.error(error_msg)\n",
        "                            add_message(\"assistant\", error_msg)\n",
        "        else:\n",
        "            st.info(\"🔄 Vui lòng upload và xử lý file PDF trước khi bắt đầu chat!\")\n",
        "            st.chat_input(\"Nhập câu hỏi của bạn...\", disabled=True)\n",
        "    else:\n",
        "        st.info(\"⏳ Đang tải AI models, vui lòng đợi...\")\n",
        "        st.chat_input(\"Nhập câu hỏi của bạn...\", disabled=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6949dqu3FfKm",
        "outputId": "07946b3f-9336-4e9a-f82c-a79ad86efa3f"
      },
      "outputs": [],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_87Lv_kFkWZ",
        "outputId": "77e1c99e-5443-4642-c99e-0efc05350a70"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a23b9dc7d4b4efd87308988543d3548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67f5058891e7445aae685fd890858f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68e737338124406886eadc213e795e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "721f0de8be334f9eba92d53b42641efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b21177907b42df88196db158796998",
            "placeholder": "​",
            "style": "IPY_MODEL_67f5058891e7445aae685fd890858f02",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "74d64024f3134bff9de5a74b016c465e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_721f0de8be334f9eba92d53b42641efb",
              "IPY_MODEL_d73b132ad9c7406ea0937ed0ee44040b",
              "IPY_MODEL_de817b71954442dbbc24da36871123ef"
            ],
            "layout": "IPY_MODEL_f088a9462bee45ebafe97cb9e3f38cf7"
          }
        },
        "83b20f9c7ed345eead1612addf4fff58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d22f24bdeb24fb4b49e14ac53262c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73b132ad9c7406ea0937ed0ee44040b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83b20f9c7ed345eead1612addf4fff58",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68e737338124406886eadc213e795e6c",
            "value": 2
          }
        },
        "de817b71954442dbbc24da36871123ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d22f24bdeb24fb4b49e14ac53262c0c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a23b9dc7d4b4efd87308988543d3548",
            "value": " 2/2 [01:19&lt;00:00, 36.55s/it]"
          }
        },
        "e6b21177907b42df88196db158796998": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f088a9462bee45ebafe97cb9e3f38cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
