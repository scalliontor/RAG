{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74d64024f3134bff9de5a74b016c465e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_721f0de8be334f9eba92d53b42641efb",
              "IPY_MODEL_d73b132ad9c7406ea0937ed0ee44040b",
              "IPY_MODEL_de817b71954442dbbc24da36871123ef"
            ],
            "layout": "IPY_MODEL_f088a9462bee45ebafe97cb9e3f38cf7"
          }
        },
        "721f0de8be334f9eba92d53b42641efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b21177907b42df88196db158796998",
            "placeholder": "​",
            "style": "IPY_MODEL_67f5058891e7445aae685fd890858f02",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d73b132ad9c7406ea0937ed0ee44040b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83b20f9c7ed345eead1612addf4fff58",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68e737338124406886eadc213e795e6c",
            "value": 2
          }
        },
        "de817b71954442dbbc24da36871123ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d22f24bdeb24fb4b49e14ac53262c0c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a23b9dc7d4b4efd87308988543d3548",
            "value": " 2/2 [01:19&lt;00:00, 36.55s/it]"
          }
        },
        "f088a9462bee45ebafe97cb9e3f38cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b21177907b42df88196db158796998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f5058891e7445aae685fd890858f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83b20f9c7ed345eead1612addf4fff58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e737338124406886eadc213e795e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d22f24bdeb24fb4b49e14ac53262c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a23b9dc7d4b4efd87308988543d3548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lZ6HT69itq5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc068be1-3296-4329-ce62-8506bf69ea49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 29 18:40:50 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0             30W /   70W |    7374MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Set up\n"
      ],
      "metadata": {
        "id": "H2oUzxHg2lto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers==4.52.4\n",
        "!pip install -q bitsandbytes==0.46.0\n",
        "!pip install -q accelerate==1.7.0\n",
        "!pip install -q langchain==0.3.25\n",
        "!pip install -q langchainhub==0.1.21\n",
        "!pip install -q langchain-chroma==0.2.4\n",
        "!pip install -q langchain_experimental==0.3.4\n",
        "!pip install -q langchain-community==0.3.24\n",
        "!pip install -q langchain_huggingface==0.2.0\n",
        "!pip install -q python-dotenv==1.1.0\n",
        "!pip install -q pypdf"
      ],
      "metadata": {
        "id": "9TH8rnJqvUfk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain import hub"
      ],
      "metadata": {
        "id": "Q_Hnisfzvfjy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1lWuq0COKnU9mCfMvTEq54DBLgAh3yYDx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpa9SA3M0wYm",
        "outputId": "f0e149ce-a178-4d32-81e8-739ad8b7d7c2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lWuq0COKnU9mCfMvTEq54DBLgAh3yYDx\n",
            "To: /content/YOLOv10_Tutorials.pdf\n",
            "100% 16.6M/16.6M [00:00<00:00, 39.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v1KzMsS92ke6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Load file\n"
      ],
      "metadata": {
        "id": "UXllLSBH2qI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Loader = PyPDFLoader\n",
        "file_path = \"/content/YOLOv10_Tutorials.pdf\"\n",
        "loader = Loader(file_path)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "IyeXHLY6v7Gf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Embeddings"
      ],
      "metadata": {
        "id": "SZwsI3or2tqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chọn model**"
      ],
      "metadata": {
        "id": "JIh-2oPx3X-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"bkai-foundation-models/vietnamese-bi-encoder\"\n",
        ")"
      ],
      "metadata": {
        "id": "OgaPIeaFwwdS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3FV-3NhxNez",
        "outputId": "74b1909f-9383-4ddd-9f3f-966c60a6d3a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(model_name='bkai-foundation-models/vietnamese-bi-encoder', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Phương pháp phân đoạn tài liệu**"
      ],
      "metadata": {
        "id": "QLFmSBV-3NIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Phan doan tai lieu\n",
        "\n",
        "semantic_splitter = SemanticChunker(\n",
        "    embeddings = embeddings, #embeddings model\n",
        "    breakpoint_threshold_type = \"percentile\",\n",
        "    breakpoint_threshold_amount = 95, #5% nho nhat => tách (ngưỡng lấy theo phân vị của phân phối)\n",
        "    min_chunk_size = 500, #mỗi một đoạn có ít nhất 500 kí tự\n",
        "    add_start_index = True, #khi mà tiến hành phân đoạn, đánh tham số thứ tự các đoạn bị phân ra\n",
        ")"
      ],
      "metadata": {
        "id": "y2KLwk2_xSD5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chạy phân đoạn**"
      ],
      "metadata": {
        "id": "tFltXHk44Agl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = semantic_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "K5JsRdOdyZyJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YooQOByayq6b",
        "outputId": "013fe3c2-6db7-4eba-8d77-50331c945c2a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0L02m_hyvIt",
        "outputId": "fd1f174e-ebd7-4204-9909-789f2e470e8d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-06-20T11:06:10+00:00', 'author': '', 'keywords': '', 'moddate': '2024-06-20T11:06:10+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': 'Overleaf Example', 'trapped': '/False', 'source': '/content/YOLOv10_Tutorials.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1', 'start_index': 0}, page_content='AI VIET NAM – AI COURSE 2024\\nTutorial: Phát hiện đối tượng trong ảnh với\\nYOLOv10\\nDinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui và\\nQuang-Vinh Dinh\\nNgày 20 tháng 6 năm 2024\\nI. Giới thiệu\\nObject Detection (Tạm dịch: Phát hiện đối tượng)là một bài toán cổ điển thuộc lĩnh vực\\nComputer Vision. Mục tiêu của bài toán này là tự động xác định vị trí của các đối tượng trong\\nmột tấm ảnh. Tính tới thời điểm hiện tại, đã có rất nhiều phương pháp được phát triển nhằm\\ngiải quyết hiệu quả bài toán này. Trong đó, các phương pháp thuộc họ YOLO (You Only Look\\nOnce) thu hút được sự chú ý rất lớn từ cộng đồng nghiên cứu bởi độ chính xác và tốc độ thực\\nthi mà loại mô hình này mang lại. Hình 1: Logo của mô hình YOLO. Ảnh: link. Thời gian vừa qua, Ao Wang và các cộng sự tại Đại học Thanh Hoa (Tsinghua University)\\nđã đề xuất mô hìnhYOLOv10 trong bài báoYOLOv10: Real-Time End-to-End Object\\nDetection [10]. Với những cải tiến mới, mô hình đã đạt được hiệu suất vượt trội hơn so với các\\nphiên bản YOLO trước đó ở các khía cạnh khác nhau, tăng cường khả năng phát hiện đối tượng\\ntheo thời gian thực (real-time object detection). 1')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lưu các đoạn thành vector trong cơ sở dữ liệu**"
      ],
      "metadata": {
        "id": "gIy8C-mc4Mxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = Chroma.from_documents(\n",
        "    documents = docs,\n",
        "    embedding = embeddings, #chuyển docs -> vector / lưu trữ vector\n",
        ")#định nghĩa vector data base\n",
        "\n",
        "retriever = vector_db.as_retriever() # khởi tạo vector retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIm_ALXIywD1",
        "outputId": "86dec181-1100-49a2-8b4f-2d5b7ea60476"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Retriever"
      ],
      "metadata": {
        "id": "xVBizCNI5AaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"YOLOv10 dùng để làm gì\"\n",
        "result = retriever.invoke(query) #invoke chuyển câu query thành vector, xong truy vấn\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqC8mxl9zQ7K",
        "outputId": "a62ca9a3-0df5-434f-e5fe-ba03a9c74d0a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(id='8b8f4339-a41a-40a1-84ef-0c48f1f1040e', metadata={'creator': 'LaTeX with hyperref', 'title': 'Overleaf Example', 'page': 1, 'subject': '', 'total_pages': 20, 'producer': 'pdfTeX-1.40.25', 'start_index': 0, 'creationdate': '2024-06-20T11:06:10+00:00', 'moddate': '2024-06-20T11:06:10+00:00', 'trapped': '/False', 'keywords': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'author': '', 'source': '/content/YOLOv10_Tutorials.pdf', 'page_label': '2'}, page_content='AI VIETNAM (AIO2024) aivietnam.edu.vn\\nHình 2: Hiệu suất của YOLOv10 khi so sánh với các mô hình khác. Trên tập dữ liệu COCO,\\nYOLOv10 đạt được kết quả tốt nhất về khía cạnh Độ trễ (Latency) và Số lượng tham số mô\\nhình (Number of parameters) trong khi vẫn giữ được độ chính xác (COCO AP) cao. Ảnh: [10]. Trong bài viết này, chúng ta sẽ cùng nhau tìm hiểu về YOLOv10 và cách sử dụng mô hình này. Thông qua đó, nhóm cũng sẽ trình bày sơ lược về bài toán Object Detection cũng như tóm tắt\\nngắn gọn các phiên bản YOLO trước đó để bạn đọc có một cái nhìn tổng quan hơn về nội dung\\nnày. Theo đó, bài viết được bố cục như sau:\\n- Phần I:Giới thiệu về nội dung bài viết. - Phần II:Tóm tắt về bài toán Object Detection và các phiên bản YOLO đời trước. - Phần III:Trình bày nội dung YOLOv10. - Phần IV:Hướng dẫn cách cài đặt, huấn luyện và sử dụng YOLOv10. - Phần V:Trích dẫn tài liệu. 2'), Document(id='1935d723-5a90-40a7-9d60-fea91bbeeae5', metadata={'start_index': 0, 'producer': 'pdfTeX-1.40.25', 'page': 1, 'creationdate': '2024-06-20T11:06:10+00:00', 'keywords': '', 'page_label': '2', 'title': 'Overleaf Example', 'creator': 'LaTeX with hyperref', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 20, 'trapped': '/False', 'author': '', 'moddate': '2024-06-20T11:06:10+00:00', 'source': '/content/YOLOv10_Tutorials.pdf', 'subject': ''}, page_content='AI VIETNAM (AIO2024) aivietnam.edu.vn\\nHình 2: Hiệu suất của YOLOv10 khi so sánh với các mô hình khác. Trên tập dữ liệu COCO,\\nYOLOv10 đạt được kết quả tốt nhất về khía cạnh Độ trễ (Latency) và Số lượng tham số mô\\nhình (Number of parameters) trong khi vẫn giữ được độ chính xác (COCO AP) cao. Ảnh: [10]. Trong bài viết này, chúng ta sẽ cùng nhau tìm hiểu về YOLOv10 và cách sử dụng mô hình này. Thông qua đó, nhóm cũng sẽ trình bày sơ lược về bài toán Object Detection cũng như tóm tắt\\nngắn gọn các phiên bản YOLO trước đó để bạn đọc có một cái nhìn tổng quan hơn về nội dung\\nnày. Theo đó, bài viết được bố cục như sau:\\n- Phần I:Giới thiệu về nội dung bài viết. - Phần II:Tóm tắt về bài toán Object Detection và các phiên bản YOLO đời trước. - Phần III:Trình bày nội dung YOLOv10. - Phần IV:Hướng dẫn cách cài đặt, huấn luyện và sử dụng YOLOv10. - Phần V:Trích dẫn tài liệu. 2'), Document(id='7c0bd0d6-9846-431a-a87e-19369cbb8d15', metadata={'start_index': 0, 'page_label': '9', 'author': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'moddate': '2024-06-20T11:06:10+00:00', 'page': 8, 'total_pages': 20, 'creationdate': '2024-06-20T11:06:10+00:00', 'source': '/content/YOLOv10_Tutorials.pdf', 'title': 'Overleaf Example', 'keywords': '', 'producer': 'pdfTeX-1.40.25', 'subject': '', 'creator': 'LaTeX with hyperref', 'trapped': '/False'}, page_content='AI VIETNAM (AIO2024) aivietnam.edu.vn\\nIII. YOLOv10: Real-Time End-to-End\\nObject Detection\\nAo Wang và các cộng sự đã đặt nghi vấn về sự tối ưu trong việc phụ thuộc vào kỹ thuật hậu xử\\nlý Non-maximum Suppresion (NMS) và cách thiết kế mô hình của các phiên bản YOLO trước\\nđó. Với các hạn chế quan sát được từ hai điều trên và mục tiêu xây dựng một mô hình object\\ndetection thời gian thực, YOLOv10 đã được đề xuất với những thay đổi mới. Theo đó, có hai\\nđiểm nhấn chính trong phương pháp mà nhóm tác giả YOLOv10 đề xuất bao gồm:\\n1. Consistent Dual Assignments for NMS-free Training:Trong quá trình dự đoán của\\ncác mạng YOLO đời trước, rất nhiều bounding box được mô hình đưa ra (ví dụ: anchors\\nbox,...) và nhiệm vụ của chúng ta là tìm ra đại diện chính xác nhất cho mỗi vật thể có\\ntrong ảnh. Để tận dụng tối đa các đề xuất bounding box đúng trong việc huấn luyện,\\ncác phương pháp thường ứng dụng kỹ thuật Task Alignment Learning (TAL). Trong đó,\\nchiến lược one-to-many label assignment được áp dụng để gán các bounding box “positive”\\n(bounding box chính xác) vào ground-truth của vật thể tương ứng để tăng cường khả năng\\nnhận biết vật thể của mô hình. Tuy vậy, việc này lại gây ra độ trễ (latency) lớn trong quá\\ntrình inference của mô hình bởi việc phụ thuộc vào thuật toán NMS để lọc các dự đoán\\nthừa. Một cách tiếp cận khác đó là sử dụng chiến lược one-to-one label assignment, bằng cách\\nchỉ gán một đề xuất bouding box “positive” với ground-truth của vật thể tương ứng, qua\\nđó tránh việc hậu xử lý với NMS. Tuy vậy, chiến lược này lại dẫn đến hiệu suất mô hình\\nkhông được tốt. Hình 10: Minh họa chiến lược one-to-one và one-to-many label assignemnts. 9'), Document(id='ed9c48cd-8da2-4fc4-9bec-6477bc0c4c13', metadata={'title': 'Overleaf Example', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': '/content/YOLOv10_Tutorials.pdf', 'creationdate': '2024-06-20T11:06:10+00:00', 'page_label': '9', 'subject': '', 'start_index': 0, 'page': 8, 'trapped': '/False', 'producer': 'pdfTeX-1.40.25', 'total_pages': 20, 'keywords': '', 'moddate': '2024-06-20T11:06:10+00:00', 'author': '', 'creator': 'LaTeX with hyperref'}, page_content='AI VIETNAM (AIO2024) aivietnam.edu.vn\\nIII. YOLOv10: Real-Time End-to-End\\nObject Detection\\nAo Wang và các cộng sự đã đặt nghi vấn về sự tối ưu trong việc phụ thuộc vào kỹ thuật hậu xử\\nlý Non-maximum Suppresion (NMS) và cách thiết kế mô hình của các phiên bản YOLO trước\\nđó. Với các hạn chế quan sát được từ hai điều trên và mục tiêu xây dựng một mô hình object\\ndetection thời gian thực, YOLOv10 đã được đề xuất với những thay đổi mới. Theo đó, có hai\\nđiểm nhấn chính trong phương pháp mà nhóm tác giả YOLOv10 đề xuất bao gồm:\\n1. Consistent Dual Assignments for NMS-free Training:Trong quá trình dự đoán của\\ncác mạng YOLO đời trước, rất nhiều bounding box được mô hình đưa ra (ví dụ: anchors\\nbox,...) và nhiệm vụ của chúng ta là tìm ra đại diện chính xác nhất cho mỗi vật thể có\\ntrong ảnh. Để tận dụng tối đa các đề xuất bounding box đúng trong việc huấn luyện,\\ncác phương pháp thường ứng dụng kỹ thuật Task Alignment Learning (TAL). Trong đó,\\nchiến lược one-to-many label assignment được áp dụng để gán các bounding box “positive”\\n(bounding box chính xác) vào ground-truth của vật thể tương ứng để tăng cường khả năng\\nnhận biết vật thể của mô hình. Tuy vậy, việc này lại gây ra độ trễ (latency) lớn trong quá\\ntrình inference của mô hình bởi việc phụ thuộc vào thuật toán NMS để lọc các dự đoán\\nthừa. Một cách tiếp cận khác đó là sử dụng chiến lược one-to-one label assignment, bằng cách\\nchỉ gán một đề xuất bouding box “positive” với ground-truth của vật thể tương ứng, qua\\nđó tránh việc hậu xử lý với NMS. Tuy vậy, chiến lược này lại dẫn đến hiệu suất mô hình\\nkhông được tốt. Hình 10: Minh họa chiến lược one-to-one và one-to-many label assignemnts. 9')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCKasOnYzrYi",
        "outputId": "551ace39-0942-47e0-f831-6350892155d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK3rZVpBzyZs",
        "outputId": "3c2355e3-7069-451a-c913-a5d101e3831b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Hình 2: Hiệu suất của YOLOv10 khi so sánh với các mô hình khác. Trên tập dữ liệu COCO,\n",
            "YOLOv10 đạt được kết quả tốt nhất về khía cạnh Độ trễ (Latency) và Số lượng tham số mô\n",
            "hình (Number of parameters) trong khi vẫn giữ được độ chính xác (COCO AP) cao. Ảnh: [10]. Trong bài viết này, chúng ta sẽ cùng nhau tìm hiểu về YOLOv10 và cách sử dụng mô hình này. Thông qua đó, nhóm cũng sẽ trình bày sơ lược về bài toán Object Detection cũng như tóm tắt\n",
            "ngắn gọn các phiên bản YOLO trước đó để bạn đọc có một cái nhìn tổng quan hơn về nội dung\n",
            "này. Theo đó, bài viết được bố cục như sau:\n",
            "- Phần I:Giới thiệu về nội dung bài viết. - Phần II:Tóm tắt về bài toán Object Detection và các phiên bản YOLO đời trước. - Phần III:Trình bày nội dung YOLOv10. - Phần IV:Hướng dẫn cách cài đặt, huấn luyện và sử dụng YOLOv10. - Phần V:Trích dẫn tài liệu. 2' metadata={'creator': 'LaTeX with hyperref', 'title': 'Overleaf Example', 'page': 1, 'subject': '', 'total_pages': 20, 'producer': 'pdfTeX-1.40.25', 'start_index': 0, 'creationdate': '2024-06-20T11:06:10+00:00', 'moddate': '2024-06-20T11:06:10+00:00', 'trapped': '/False', 'keywords': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'author': '', 'source': '/content/YOLOv10_Tutorials.pdf', 'page_label': '2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. LLM\n"
      ],
      "metadata": {
        "id": "qY7J_VNa2Wun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nf4_config = BitsAndBytesConfig(\n",
        "    ### Your Code Here\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_use_double_quant = True,\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "    bnb_4bit_compute_dtype = torch.bfloat16, #quantization\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config = nf4_config,\n",
        "    device_map = \"auto\",\n",
        "    low_cpu_mem_usage = True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) #bộ tách từ\n",
        "\n",
        "model_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,# phản hồi tối đa sinh ra 512 token\n",
        "    pad_token_id=tokenizer.eos_token_id, # keyworkd đánh dấu kết thúc sinh\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline=model_pipeline,\n",
        ")\n",
        "#text đầu vào => tokenizer => model => generate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "74d64024f3134bff9de5a74b016c465e",
            "721f0de8be334f9eba92d53b42641efb",
            "d73b132ad9c7406ea0937ed0ee44040b",
            "de817b71954442dbbc24da36871123ef",
            "f088a9462bee45ebafe97cb9e3f38cf7",
            "e6b21177907b42df88196db158796998",
            "67f5058891e7445aae685fd890858f02",
            "83b20f9c7ed345eead1612addf4fff58",
            "68e737338124406886eadc213e795e6c",
            "8d22f24bdeb24fb4b49e14ac53262c0c",
            "2a23b9dc7d4b4efd87308988543d3548"
          ]
        },
        "id": "uWOd8WXwz3vr",
        "outputId": "5f609cfe-8d8d-4333-f375-aa32e1fc9134"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74d64024f3134bff9de5a74b016c465e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Prompting\n"
      ],
      "metadata": {
        "id": "D4cxc0K-C7vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "# input variables = [context, question]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oYgjFm74Q_Y",
        "outputId": "7443a722-caad-4f8e-957e-0ef6e7f2c7e0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "d0SJ-KZ-DaZG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"content\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "#chain: retriever(content) -> format_docs(question) => RunnablePassthrough:\n",
        "#pass vào content question để tìm các đoạn phù hợp\n",
        "#Đẩy vào prompt -> chạy qua LLM ->"
      ],
      "metadata": {
        "id": "u2dHHTdN4mVi"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = \"YOLOv10 là gì?\"\n",
        "output = rag_chain.invoke(user_question)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xoe-6EnE5qHB",
        "outputId": "63a7c2b0-1fec-45ef-b6eb-e188e1415fc6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: YOLOv10 là gì? \n",
            "Context: YOLOv9\n",
            "YOLOv9 [9] được giới thiệu vào năm 2024 bởi Chien-Yao Wang, I-Hau Yeh, và Hong-Yuan Mark\n",
            "Liao. Mô hình này cải thiện độ chính xác và tốc độ so với YOLOv8 và giới thiệu nhiều kỹ thuật\n",
            "mới như Programmable Gradient Information (PGI) và Generalized Efficient Layer Aggregation\n",
            "Network (GELAN). 7\n",
            "\n",
            "YOLOv9\n",
            "YOLOv9 [9] được giới thiệu vào năm 2024 bởi Chien-Yao Wang, I-Hau Yeh, và Hong-Yuan Mark\n",
            "Liao. Mô hình này cải thiện độ chính xác và tốc độ so với YOLOv8 và giới thiệu nhiều kỹ thuật\n",
            "mới như Programmable Gradient Information (PGI) và Generalized Efficient Layer Aggregation\n",
            "Network (GELAN). 7\n",
            "\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Hình 2: Hiệu suất của YOLOv10 khi so sánh với các mô hình khác. Trên tập dữ liệu COCO,\n",
            "YOLOv10 đạt được kết quả tốt nhất về khía cạnh Độ trễ (Latency) và Số lượng tham số mô\n",
            "hình (Number of parameters) trong khi vẫn giữ được độ chính xác (COCO AP) cao. Ảnh: [10]. Trong bài viết này, chúng ta sẽ cùng nhau tìm hiểu về YOLOv10 và cách sử dụng mô hình này. Thông qua đó, nhóm cũng sẽ trình bày sơ lược về bài toán Object Detection cũng như tóm tắt\n",
            "ngắn gọn các phiên bản YOLO trước đó để bạn đọc có một cái nhìn tổng quan hơn về nội dung\n",
            "này. Theo đó, bài viết được bố cục như sau:\n",
            "- Phần I:Giới thiệu về nội dung bài viết. - Phần II:Tóm tắt về bài toán Object Detection và các phiên bản YOLO đời trước. - Phần III:Trình bày nội dung YOLOv10. - Phần IV:Hướng dẫn cách cài đặt, huấn luyện và sử dụng YOLOv10. - Phần V:Trích dẫn tài liệu. 2\n",
            "\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Hình 2: Hiệu suất của YOLOv10 khi so sánh với các mô hình khác. Trên tập dữ liệu COCO,\n",
            "YOLOv10 đạt được kết quả tốt nhất về khía cạnh Độ trễ (Latency) và Số lượng tham số mô\n",
            "hình (Number of parameters) trong khi vẫn giữ được độ chính xác (COCO AP) cao. Ảnh: [10]. Trong bài viết này, chúng ta sẽ cùng nhau tìm hiểu về YOLOv10 và cách sử dụng mô hình này. Thông qua đó, nhóm cũng sẽ trình bày sơ lược về bài toán Object Detection cũng như tóm tắt\n",
            "ngắn gọn các phiên bản YOLO trước đó để bạn đọc có một cái nhìn tổng quan hơn về nội dung\n",
            "này. Theo đó, bài viết được bố cục như sau:\n",
            "- Phần I:Giới thiệu về nội dung bài viết. - Phần II:Tóm tắt về bài toán Object Detection và các phiên bản YOLO đời trước. - Phần III:Trình bày nội dung YOLOv10. - Phần IV:Hướng dẫn cách cài đặt, huấn luyện và sử dụng YOLOv10. - Phần V:Trích dẫn tài liệu. 2 \n",
            "Answer: YOLOv10 là một phiên bản mới của hệ thống dự đoán đối tượng (Object Detection) được giới thiệu vào năm 2024 bởi Chien-Yao Wang, I-Hau Yeh, và Hong-Yuan Mark Liao. Mô hình này cải thiện độ chính xác và tốc độ so với YOLOv8 và giới thiệu nhiều kỹ thuật mới như Programmable Gradient Information (PGI) và Generalized Efficient Layer Aggregation Network (GELAN). YOLOv10 đạt được kết quả tốt nhất về khía cạnh Độ trễ (Latency) và Số lượng tham số mô hình (Number of parameters) trong khi vẫn giữ được độ chính xác (COCO AP) cao.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit Deployment"
      ],
      "metadata": {
        "id": "_Y-P1rtmFVSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit==1.46.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-Iy8W7mFM54",
        "outputId": "cb855127-b2f7-4b37-8be0-661a1904b5f3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "import torch\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import time\n",
        "\n",
        "if 'models_loaded' not in st.session_state:\n",
        "    st.session_state.models_loaded = None\n",
        "if 'rag_chain' not in st.session_state:\n",
        "    st.session_state.rag_chain = None\n",
        "if 'models_loaded' not in st.session_state:\n",
        "    st.session_state.models_loaded = False\n",
        "if 'embeddings' not in st.session_state:\n",
        "    st.session_state.embeddings = None\n",
        "if 'llm' not in st.session_state:\n",
        "    st.session_state.llm = None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_embeddings():\n",
        "    return HuggingFaceEmbeddings(model_name=\"bkai-foundation-models/vietnamese-bi-encoder\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_llm():\n",
        "    MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    model_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    return HuggingFacePipeline(pipeline=model_pipeline)\n",
        "\n",
        "def process_pdf(uploaded_file):\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
        "        tmp_file.write(uploaded_file.getvalue())\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    loader = PyPDFLoader(tmp_file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    semantic_splitter = SemanticChunker(\n",
        "        embeddings=st.session_state.embeddings,\n",
        "        buffer_size=1,\n",
        "        breakpoint_threshold_type=\"percentile\",\n",
        "        breakpoint_threshold_amount=95,\n",
        "        min_chunk_size=500,\n",
        "        add_start_index=True\n",
        "    )\n",
        "\n",
        "    docs = semantic_splitter.split_documents(documents)\n",
        "    vector_db = Chroma.from_documents(documents=docs, embedding=st.session_state.embeddings)\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | st.session_state.llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    os.unlink(tmp_file_path)\n",
        "    return rag_chain, len(docs)\n",
        "\n",
        "\n",
        "def add_message(role, content):\n",
        "    \"\"\"Thêm tin nhắn vào lịch sử chat\"\"\"\n",
        "    st.session_state.chat_history.append({\n",
        "        \"role\": role,\n",
        "        \"content\": content,\n",
        "        \"timestamp\": time.time()\n",
        "    })\n",
        "\n",
        "def clear_chat():\n",
        "    \"\"\"Xóa lịch sử chat\"\"\"\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "def display_chat():\n",
        "    \"\"\"Hiển thị lịch sử chat\"\"\"\n",
        "    if st.session_state.chat_history:\n",
        "        for message in st.session_state.chat_history:\n",
        "            if message[\"role\"] == \"user\":\n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(message[\"content\"])\n",
        "            else:\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    st.write(message[\"content\"])\n",
        "    else:\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.write(\"Xin chào! Tôi là AI assistant. Hãy upload file PDF và bắt đầu đặt câu hỏi về nội dung tài liệu nhé! 😊\")\n",
        "\n",
        "# UI\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"PDF RAG Chatbot\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "    st.title(\"PDF RAG Assistant\")\n",
        "    st.logo(\"./logo.png\", size=\"large\")\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.title(\"⚙️ Cài đặt\")\n",
        "\n",
        "        # Load models\n",
        "        if not st.session_state.models_loaded:\n",
        "            st.warning(\"⏳ Đang tải models...\")\n",
        "            with st.spinner(\"Đang tải AI models...\"):\n",
        "                st.session_state.embeddings = load_embeddings()\n",
        "                st.session_state.llm = load_llm()\n",
        "                st.session_state.models_loaded = True\n",
        "            st.success(\"✅ Models đã sẵn sàng!\")\n",
        "            st.rerun()\n",
        "        else:\n",
        "            st.success(\"✅ Models đã sẵn sàng!\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Upload PDF\n",
        "        st.subheader(\"📄 Upload tài liệu\")\n",
        "        uploaded_file = st.file_uploader(\"Chọn file PDF\", type=\"pdf\")\n",
        "\n",
        "        if uploaded_file:\n",
        "            if st.button(\"🔄 Xử lý PDF\", use_container_width=True):\n",
        "                with st.spinner(\"Đang xử lý PDF...\"):\n",
        "                    st.session_state.rag_chain, num_chunks = process_pdf(uploaded_file)\n",
        "                    st.session_state.pdf_processed = True\n",
        "                    st.session_state.pdf_name = uploaded_file.name\n",
        "                    # Reset chat history khi upload PDF mới\n",
        "                    clear_chat()\n",
        "                    add_message(\"assistant\", f\"✅ Đã xử lý thành công file **{uploaded_file.name}**!\\n\\n📊 Tài liệu được chia thành {num_chunks} phần. Bạn có thể bắt đầu đặt câu hỏi về nội dung tài liệu.\")\n",
        "                st.rerun()\n",
        "\n",
        "        # PDF status\n",
        "        if st.session_state.pdf_processed:\n",
        "            st.success(f\"📄 Đã tải: {st.session_state.pdf_name}\")\n",
        "        else:\n",
        "            st.info(\"📄 Chưa có tài liệu\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Chat controls\n",
        "        st.subheader(\"💬 Điều khiển Chat\")\n",
        "        if st.button(\"🗑️ Xóa lịch sử chat\", use_container_width=True):\n",
        "            clear_chat()\n",
        "            st.rerun()\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Instructions\n",
        "        st.subheader(\"📋 Hướng dẫn\")\n",
        "        st.markdown(\"\"\"\n",
        "        **Cách sử dụng:**\n",
        "        1. **Upload PDF** - Chọn file và nhấn \"Xử lý PDF\"\n",
        "        2. **Đặt câu hỏi** - Nhập câu hỏi trong ô chat\n",
        "        3. **Nhận trả lời** - AI sẽ trả lời dựa trên nội dung PDF\n",
        "        \"\"\")\n",
        "\n",
        "    # Main content\n",
        "    st.markdown(\"*Trò chuyện với Chatbot để trao đổi về nội dung tài liệu PDF của bạn*\")\n",
        "\n",
        "    # Chat container\n",
        "    chat_container = st.container()\n",
        "\n",
        "    with chat_container:\n",
        "        # Display chat history\n",
        "        display_chat()\n",
        "\n",
        "    # Chat input\n",
        "    if st.session_state.models_loaded:\n",
        "        if st.session_state.pdf_processed:\n",
        "            # User input\n",
        "            user_input = st.chat_input(\"Nhập câu hỏi của bạn...\")\n",
        "\n",
        "            if user_input:\n",
        "                # Add user message\n",
        "                add_message(\"user\", user_input)\n",
        "\n",
        "                # Display user message immediately\n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(user_input)\n",
        "\n",
        "                # Generate response\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    with st.spinner(\"Đang suy nghĩ...\"):\n",
        "                        try:\n",
        "                            output = st.session_state.rag_chain.invoke(user_input)\n",
        "                            # Clean up the response\n",
        "                            if 'Answer:' in output:\n",
        "                                answer = output.split('Answer:')[1].strip()\n",
        "                            else:\n",
        "                                answer = output.strip()\n",
        "\n",
        "                            # Display response\n",
        "                            st.write(answer)\n",
        "\n",
        "                            # Add assistant message to history\n",
        "                            add_message(\"assistant\", answer)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            error_msg = f\"Xin lỗi, đã có lỗi xảy ra: {str(e)}\"\n",
        "                            st.error(error_msg)\n",
        "                            add_message(\"assistant\", error_msg)\n",
        "        else:\n",
        "            st.info(\"🔄 Vui lòng upload và xử lý file PDF trước khi bắt đầu chat!\")\n",
        "            st.chat_input(\"Nhập câu hỏi của bạn...\", disabled=True)\n",
        "    else:\n",
        "        st.info(\"⏳ Đang tải AI models, vui lòng đợi...\")\n",
        "        st.chat_input(\"Nhập câu hỏi của bạn...\", disabled=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ch8jWkuFbiX",
        "outputId": "310c382f-e122-4e42-92fe-14ead73ff2f3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6949dqu3FfKm",
        "outputId": "07946b3f-9336-4e9a-f82c-a79ad86efa3f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.16.176.254"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_87Lv_kFkWZ",
        "outputId": "77e1c99e-5443-4642-c99e-0efc05350a70"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.176.254:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://wise-bags-mix.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}